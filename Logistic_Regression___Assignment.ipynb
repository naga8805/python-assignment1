{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**"
      ],
      "metadata": {
        "id": "FwGWnaDtpaGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Logistic Regression is a supervised machine learning algorithm used for binary or multiclass classification problems. It models the probability that a given input belongs to a certain class using the logistic (sigmoid) function.\n",
        "\n",
        "**Here's a Difference:**\n",
        "\n",
        "**Linear Regression:**\n",
        "\n",
        "* **Purpose:** Predicts a continuous dependent variable (e.g., house price, temperature) based on independent variables.\n",
        "* **Output:** A continuous numerical value.\n",
        "* **Example:** Predicting the price of a house based on its size, location, and number of bedrooms.\n",
        "* **Method:** Uses the least squares method to find the best-fitting line.\n",
        "* **Key Assumption:** Linear relationship between the independent and dependent variables.\n",
        "\n",
        "**Logistic Regression:**\n",
        "\n",
        "* **Purpose:** Predicts the probability of a binary outcome (e.g., spam/not spam, pass/fail) based on independent variables.\n",
        "* **Output:** A probability value between 0 and 1, which is then often converted to a binary classification (e.g., above 0.5 is 1, below 0.5 is 0).\n",
        "* **Example:** Predicting whether a customer will click on an advertisement based on their demographics and browsing history.\n",
        "* **Method:** Uses maximum likelihood estimation to find the best-fitting sigmoid curve.\n",
        "* **Key Assumption:** The relationship between the independent variables and the log-odds of the outcome is linear."
      ],
      "metadata": {
        "id": "VOJ8kivRtJOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n"
      ],
      "metadata": {
        "id": "Sg1XI2EWplRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Logistic Regression, the sigmoid function serves to transform the output of a linear model into a probability score, mapping any real number to a value between 0 and 1. This is crucial because it allows the model to predict the probability of a binary outcome, like \"yes\" or \"no\", \"spam\" or \"not spam\". The sigmoid function ensures the output falls within the valid probability range (0 to 1) and is essential for interpreting the model's predictions as probabilities.\n",
        "\n",
        "**Here's a more detailed explanation:**\n",
        "\n",
        "**Linear Combination:**\n",
        "\n",
        "Logistic regression begins by calculating a linear combination of the input features and their corresponding weights, similar to linear regression.\n",
        "\n",
        "**Sigmoid Transformation:**\n",
        "\n",
        "This linear output is then passed through the sigmoid function, which is defined as g(z) = 1 / (1 + e^(-z)). Where 'z' is the result of the linear combination.\n",
        "\n",
        "**Probability Output:**\n",
        "\n",
        "The sigmoid function maps any real number (positive, negative, or zero) to a value between 0 and 1. This output represents the probability that the input belongs to the positive class.\n",
        "\n",
        "**Threshold for Classification:**\n",
        "\n",
        "A threshold, typically 0.5, is then used to convert the probability into a binary classification. If the probability is above the threshold, the input is classified as belonging to the positive class; otherwise, it's classified as belonging to the negative class."
      ],
      "metadata": {
        "id": "wmbJU7ozz8Da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: What is Regularization in Logistic Regression and why is it needed?**"
      ],
      "metadata": {
        "id": "_dc847MWpn5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Regularization in logistic regression is a technique used to prevent overfitting, a phenomenon where a model learns the training data too well, including its noise, and performs poorly on new, unseen data. By adding a penalty term to the loss function, regularization discourages overly complex models and promotes better generalization to new data.\n",
        "\n",
        "**Why is Regularization Needed?**\n",
        "\n",
        "Regularization is crucial in Logistic Regression for several reasons:\n",
        "\n",
        "* **Preventing Overfitting:** This is the primary reason. In scenarios with a high number of features, or when features are highly correlated, a Logistic Regression model might assign very large coefficients to some features to fit the training data perfectly. Such large coefficients indicate an overly complex model that is sensitive to minor fluctuations in the training data, leading to poor generalization on new data. Regularization introduces a penalty for large coefficients, forcing the model to simplify and be less prone to overfitting.\n",
        "\n",
        "* **Handling Multicollinearity:** When features in the dataset are highly correlated (multicollinearity), the model's coefficients can become unstable and difficult to interpret. Regularization helps to stabilize these coefficients by shrinking them, making the model more robust.\n",
        "\n",
        "\n",
        "* **Feature Selection (L1 Regularization):** Certain types of regularization, specifically L1 (Lasso) regularization, can effectively perform automatic feature selection. By driving the coefficients of less important features exactly to zero, L1 regularization effectively removes them from the model, leading to a sparser model that is simpler and more interpretable.\n",
        "\n",
        "* **Improving Model Generalization:** By controlling model complexity and reducing sensitivity to training data noise, regularization enhances the model's ability to generalize well to unseen data, which is the ultimate goal of any predictive model."
      ],
      "metadata": {
        "id": "l1Wsv0ZP1iBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: What are some common evaluation metrics for classification models, and why are they important?**"
      ],
      "metadata": {
        "id": "aWpmXwQtpuFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some common evaluation metrics for classification models include:**\n",
        "\n",
        "* **Accuracy:** This is the most straightforward metric, representing the proportion of correctly predicted instances out of the total instances. While intuitive, accuracy can be misleading, especially when dealing with imbalanced datasets where one class significantly outnumbers the other.\n",
        "\n",
        "* **Precision:** Precision measures the ratio of true positive predictions to the total positive predictions (true positives + false positives). It indicates the model's ability to avoid false positives, meaning when it predicts a positive class, how often is it correct?\n",
        "\n",
        "* **Recall (Sensitivity):** Recall, also known as sensitivity, is the ratio of true positive predictions to the total actual positive instances (true positives + false negatives). It assesses the model's ability to capture all positive instances, or how many of the actual positive cases it correctly identified?\n",
        "\n",
        "* **F1-Score:** The F1-Score is the harmonic mean of precision and recall. It provides a balanced measure, particularly useful when there's an uneven class distribution, as it considers both false positives and false negatives.\n",
        "\n",
        "* **ROC Curve and AUC (Area Under the Curve):** The Receiver Operating Characteristic (ROC) curve plots the True Positive Rate against the False Positive Rate at various threshold settings. The Area Under the Curve (AUC) measures the entire area underneath the ROC curve, providing an aggregate measure of performance across all possible classification thresholds. A higher AUC indicates better model performance in distinguishing between classes.\n",
        "\n",
        "* **Confusion Matrix:** This is a table that summarizes the performance of a classification model. It displays the number of true positives, true negatives, false positives, and false negatives, offering a detailed breakdown of correct and incorrect predictions for each class.\n",
        "\n",
        "**Why these metrics are important:**\n",
        "\n",
        "* **Model Evaluation:** They provide a quantitative way to assess the performance of a classification model.\n",
        "* **Identifying Biases:** Different metrics can highlight biases in the model's predictions, such as favoring one class over another.\n",
        "* **Task Alignment:** They help ensure that the chosen model aligns with the specific goals of the classification task.\n",
        "* **Comparison:** They allow for comparing the performance of different models or different configurations of the same model.\n",
        "* **Threshold Tuning:** Metrics like recall and precision can guide the selection of optimal decision thresholds for the model."
      ],
      "metadata": {
        "id": "uHZ3FrrQ5k4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.**\n",
        "\n",
        "**(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)**"
      ],
      "metadata": {
        "id": "52F8wkdWpxnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris # Using a built-in sklearn dataset for demonstration\n",
        "\n",
        "# --- 1. Load data into a Pandas DataFrame ---\n",
        "# Since no specific CSV file was provided, we'll use a well-known dataset from scikit-learn.\n",
        "# The Iris dataset is a classic for classification.\n",
        "iris = load_iris()\n",
        "\n",
        "# Create a DataFrame for features (X) and a Series for the target variable (y)\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "\n",
        "print(\"--- Dataset Head (Features) ---\")\n",
        "print(X.head())\n",
        "print(\"\\n--- Target Variable Value Counts ---\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\nDataset Shape: {X.shape}\")\n",
        "\n",
        "# --- 2. Split the dataset into training and testing sets ---\n",
        "# We'll use a 70% training and 30% testing split.\n",
        "# random_state ensures reproducibility of the split.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# --- 3. Train a Logistic Regression model ---\n",
        "# Initialize the Logistic Regression model.\n",
        "# max_iter is increased to ensure convergence for some datasets.\n",
        "# solver='liblinear' is a good default for smaller datasets and supports L1/L2 penalties.\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "\n",
        "# Train the model using the training data\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- 4. Make predictions and print its accuracy ---\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Accuracy on the test set: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wSSq9Vp68j7",
        "outputId": "c885cdea-1484-45db-95c0-70b9f44cdd01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Head (Features) ---\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "\n",
            "--- Target Variable Value Counts ---\n",
            "0    50\n",
            "1    50\n",
            "2    50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset Shape: (150, 4)\n",
            "\n",
            "Training set size: 105 samples\n",
            "Testing set size: 45 samples\n",
            "\n",
            "Training Logistic Regression model...\n",
            "Model training complete.\n",
            "\n",
            "Model Accuracy on the test set: 0.9778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.**\n",
        "\n",
        "**(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)**"
      ],
      "metadata": {
        "id": "qLyj9CbAqHuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Here is a complete Python program that trains a Logistic Regression model using L2 regularization (Ridge) with a dataset from the sklearn package. It prints the model coefficients and accuracy:"
      ],
      "metadata": {
        "id": "jM3bN0DY84WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with L2 regularization (default)\n",
        "model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get model coefficients\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output\n",
        "print(\"Model Coefficients:\\n\", coefficients)\n",
        "print(\"Intercept:\\n\", intercept)\n",
        "print(\"Accuracy of the model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB-_1Mqy8Ex9",
        "outputId": "c8ff9aef-acd1-4fdd-8195-27083d8f1ca1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            " [[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n",
            "Intercept:\n",
            " [0.40847797]\n",
            "Accuracy of the model: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.**\n",
        "\n",
        "**(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)**"
      ],
      "metadata": {
        "id": "qrKzcIKwqX0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Here's a Python program that trains a Logistic Regression model for multiclass classification using multi_class='ovr' (One-vs-Rest strategy) and prints the classification report. The program uses the Iris dataset from sklearn."
      ],
      "metadata": {
        "id": "K7_Yzzmg8tbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with One-vs-Rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em4faZ4G8hil",
        "outputId": "0c8b169e-8e72-481a-ac52-5404f4434ce6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.**\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "KMbrF6fVquJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Using a built-in sklearn dataset\n",
        "\n",
        "# --- 1. Load a dataset from sklearn ---\n",
        "# The Breast Cancer dataset is suitable for binary classification.\n",
        "cancer = load_breast_cancer()\n",
        "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "y = pd.Series(cancer.target)\n",
        "\n",
        "print(\"--- Dataset Head (Features) ---\")\n",
        "print(X.head())\n",
        "print(\"\\n--- Target Variable Value Counts ---\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\nDataset Shape: {X.shape}\")\n",
        "\n",
        "# --- 2. Split the dataset into training and testing sets ---\n",
        "# We'll split the data to ensure we have an unseen test set for final evaluation.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# --- 3. Define the parameter grid for GridSearchCV ---\n",
        "# 'C': Inverse of regularization strength. Smaller C means stronger regularization.\n",
        "# 'penalty': Type of regularization ('l1' for Lasso, 'l2' for Ridge).\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # A range of C values to explore\n",
        "    'penalty': ['l1', 'l2']              # Both L1 and L2 regularization\n",
        "}\n",
        "\n",
        "# --- 4. Initialize Logistic Regression model ---\n",
        "# The 'solver' must be compatible with both 'l1' and 'l2' penalties. 'liblinear' is a good choice.\n",
        "# max_iter is increased to ensure convergence for various C values.\n",
        "log_reg = LogisticRegression(solver='liblinear', max_iter=200, random_state=42)\n",
        "\n",
        "# --- 5. Apply GridSearchCV to tune hyperparameters ---\n",
        "# estimator: The model object to tune.\n",
        "# param_grid: The dictionary of hyperparameters and their values to search.\n",
        "# cv: Number of folds for cross-validation (e.g., 5-fold cross-validation).\n",
        "# scoring: The metric to optimize (e.g., 'accuracy').\n",
        "# n_jobs: Number of CPU cores to use (-1 means use all available cores).\n",
        "print(\"\\nPerforming GridSearchCV to find best hyperparameters...\")\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training data.\n",
        "# GridSearchCV will perform cross-validation internally for each combination of parameters.\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"GridSearchCV complete.\")\n",
        "\n",
        "# --- 6. Print the best parameters and best validation accuracy ---\n",
        "print(f\"\\n--- Best Parameters Found by GridSearchCV ---\")\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Validation Accuracy (from cross-validation): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# --- 7. Evaluate the best model on the unseen test set ---\n",
        "# The best_estimator_ attribute holds the model trained with the best parameters.\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"\\nTest Accuracy with the Best Model: {test_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1jPkt6c9hRB",
        "outputId": "3489e74e-e00b-4bb2-dd15-58b91a9e4ba8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Head (Features) ---\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "--- Target Variable Value Counts ---\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset Shape: (569, 30)\n",
            "\n",
            "Training set size: 398 samples\n",
            "Testing set size: 171 samples\n",
            "\n",
            "Performing GridSearchCV to find best hyperparameters...\n",
            "GridSearchCV complete.\n",
            "\n",
            "--- Best Parameters Found by GridSearchCV ---\n",
            "Best Parameters: {'C': 100, 'penalty': 'l1'}\n",
            "Best Validation Accuracy (from cross-validation): 0.9673\n",
            "\n",
            "Test Accuracy with the Best Model: 0.9766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.**\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "5QXUYEvtq6KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler # For feature scaling\n",
        "from sklearn.datasets import load_breast_cancer # Using a built-in sklearn dataset\n",
        "\n",
        "# --- 1. Load a dataset from sklearn ---\n",
        "# The Breast Cancer dataset is suitable for binary classification and has features with different scales.\n",
        "cancer = load_breast_cancer()\n",
        "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "y = pd.Series(cancer.target)\n",
        "\n",
        "print(\"--- Dataset Head (Features) ---\")\n",
        "print(X.head())\n",
        "print(\"\\n--- Target Variable Value Counts ---\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\nDataset Shape: {X.shape}\")\n",
        "\n",
        "# --- 2. Split the dataset into training and testing sets ---\n",
        "# This split is done BEFORE scaling to prevent data leakage from the test set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# --- Model WITHOUT Feature Scaling ---\n",
        "print(\"\\n--- Training Model WITHOUT Feature Scaling ---\")\n",
        "model_no_scaling = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(f\"Accuracy WITHOUT Feature Scaling: {accuracy_no_scaling:.4f}\")\n",
        "\n",
        "# --- Model WITH Feature Scaling (Standardization) ---\n",
        "print(\"\\n--- Training Model WITH Feature Scaling (Standardization) ---\")\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler ONLY on the training data and then transform both training and testing data.\n",
        "# This prevents data leakage from the test set into the scaling process.\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train Logistic Regression model with scaled data\n",
        "model_scaled = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy WITH Feature Scaling: {accuracy_scaled:.4f}\")\n",
        "\n",
        "print(\"\\n--- Comparison ---\")\n",
        "print(f\"Difference in Accuracy (Scaled - Unscaled): {accuracy_scaled - accuracy_no_scaling:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pliNw6jz-jsb",
        "outputId": "2b0dc52b-487a-4370-8746-f9205e57aa84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Head (Features) ---\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "--- Target Variable Value Counts ---\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset Shape: (569, 30)\n",
            "\n",
            "Training set size: 398 samples\n",
            "Testing set size: 171 samples\n",
            "\n",
            "--- Training Model WITHOUT Feature Scaling ---\n",
            "Accuracy WITHOUT Feature Scaling: 0.9649\n",
            "\n",
            "--- Training Model WITH Feature Scaling (Standardization) ---\n",
            "Accuracy WITH Feature Scaling: 0.9825\n",
            "\n",
            "--- Comparison ---\n",
            "Difference in Accuracy (Scaled - Unscaled): 0.0175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**\n"
      ],
      "metadata": {
        "id": "uov0mJS5rBX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "To predict customer responses in an imbalanced dataset with a 5% response rate, a logistic regression model needs careful handling. This involves splitting the data, handling imbalanced classes (e.g., using SMOTE), feature scaling, hyperparameter tuning, and proper evaluation using metrics like precision, recall, and F1-score.\n",
        "\n",
        "1. **Data Handling and Splitting:**\n",
        "\n",
        "* **Split the data:**\n",
        "Divide the dataset into training, validation, and test sets. Use stratified splitting to maintain the class distribution across all sets.\n",
        "* **Handle missing values:**\n",
        "Address missing data appropriately (e.g., imputation or removal of rows/columns).\n",
        "* **Feature engineering:**\n",
        "Create new features or transform existing ones to potentially improve model performance.\n",
        "2. **Feature Scaling:**\n",
        "\n",
        "* **Normalize or standardize:** Apply techniques like MinMaxScaler or StandardScaler to scale numerical features. This is crucial for logistic regression, as it can be sensitive to feature magnitudes.\n",
        "\n",
        "3. **Addressing Class Imbalance:**\n",
        "\n",
        "* **Oversampling:**\n",
        "Use methods like SMOTE (Synthetic Minority Oversampling Technique) to generate synthetic data points for the minority class (responders).\n",
        "* **Undersampling:**\n",
        "Consider undersampling the majority class (non-responders) to reduce the imbalance. However, this might lead to information loss.\n",
        "* **Cost-sensitive learning:**\n",
        "Assign higher costs to misclassifying the minority class in the logistic regression loss function.\n",
        "\n",
        "4. **Model Building and Hyperparameter Tuning:**\n",
        "\n",
        "* **Logistic Regression:**\n",
        "Implement the logistic regression model using a suitable library (e.g., scikit-learn).\n",
        "* **Hyperparameter tuning:**\n",
        "Optimize the model's hyperparameters (e.g., regularization strength, learning rate) using techniques like grid search or random search with cross-validation (e.g., stratified K-fold).\n",
        "\n",
        "5. **Model Evaluation:**\n",
        "\n",
        "Given the imbalanced nature, traditional accuracy is insufficient. We need metrics that specifically assess the model's ability to identify the minority class.\n",
        "\n",
        "**Why Accuracy is Insufficient:** As mentioned, a 95% accurate model that predicts \"no response\" for everyone is useless.\n",
        "\n",
        "**Crucial Metrics for Imbalanced Classification:**\n",
        "\n",
        "* **Confusion Matrix:** The first step. It provides the raw counts of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
        "\n",
        "* **TP:** Actual responders correctly predicted as responders.\n",
        "\n",
        "* **FN:** Actual responders incorrectly predicted as non-responders (missed opportunities).\n",
        "\n",
        "* **FP:** Actual non-responders incorrectly predicted as responders (wasted marketing spend).\n",
        "\n",
        "* **TN:** Actual non-responders correctly predicted as non-responders.\n",
        "\n",
        "* **Precision (of the positive class):** Precision=TP/(TP+FP). Measures the proportion of positive predictions that were actually correct. High precision means fewer wasted marketing efforts.\n",
        "\n",
        "* **Recall (of the positive class / Sensitivity):** Recall=TP/(TP+FN). Measures the proportion of actual positive cases that were correctly identified. High recall means fewer missed responders.\n",
        "\n",
        "* **F1-Score (of the positive class):** The harmonic mean of Precision and Recall. F1-Score=2×(Precision×Recall)/(Precision+Recall). It provides a balanced measure, useful when you need to consider both false positives and false negatives.\n",
        "\n",
        "* **ROC AUC (Area Under the Receiver Operating Characteristic Curve):** Plots the True Positive Rate (Recall) against the False Positive Rate at various classification thresholds. AUC measures the overall ability of the model to distinguish between the two classes. A higher AUC (closer to 1) indicates better discrimination power. It's less sensitive to class imbalance than accuracy.\n",
        "\n",
        "* **Precision-Recall Curve:** Plots Precision against Recall at various thresholds. This curve is often more informative than the ROC curve for highly imbalanced datasets, as it directly focuses on the performance of the positive class.\n",
        "\n",
        "**Business Context for Metric Selection:**\n",
        "\n",
        "* If the cost of missing a responder (False Negative) is very high (e.g., significant lost revenue), prioritize Recall.\n",
        "\n",
        "* If the cost of wasted marketing spend on non-responders (False Positive) is very high, prioritize Precision.\n",
        "\n",
        "* If both are important, F1-Score provides a good balance.\n",
        "\n",
        "* For overall model discrimination, ROC AUC is a strong choice.\n",
        "\n",
        "* The final decision threshold for the predicted probability (e.g., is probability > 0.5 a \"response\"?) should be chosen based on the desired balance between precision and recall, considering the business objective.\n",
        "\n",
        "By following this comprehensive approach, the e-commerce company can build a Logistic Regression model that effectively identifies potential campaign responders, even with a challenging imbalanced dataset, leading to more efficient and successful marketing strategies."
      ],
      "metadata": {
        "id": "QbQi5_YDAUUF"
      }
    }
  ]
}